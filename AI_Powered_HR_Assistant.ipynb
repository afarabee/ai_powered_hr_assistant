{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "history_visible": true,
      "authorship_tag": "ABX9TyNqBd6a3ODezLuwiCsUjJTY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afarabee/ai_powered_hr_assistant/blob/main/AI_Powered_HR_Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Instructions\n",
        "**Crafting an AI-Powered HR Assistant: A Use Case for Nestl√©‚Äôs HR Policy Documents**\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Overview  \n",
        "The project aims to create a conversational chatbot that responds to user inquiries using PDF document information. It requires proficiency in:\n",
        "- Extracting and converting text into numerical vectors\n",
        "- Establishing an answer-finding mechanism\n",
        "- Designing a user-friendly chatbot interface with Gradio\n",
        "\n",
        "Additionally, the project emphasizes:\n",
        "- Structuring inquiries for clear communication\n",
        "- Deploying the chatbot for practical use\n",
        "- Guaranteeing the system's accessibility and efficiency in meeting user needs\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Instructions  \n",
        "- Review the learning materials and the Gradio documentation provided for the project  \n",
        "- Read the sections on **situation, task, action, and result** carefully to understand the assignment  \n",
        "- Complete and submit the assignment through the Learning Management System (LMS)  \n",
        "- Adhere closely to the provided guidelines, ensuring your submission contains all necessary analyses and interpretations  \n",
        "\n",
        "---\n",
        "\n",
        "## üß© Situation  \n",
        "As a developer, you have received the critical task of improving the operational efficiency of **Nestl√©'s Human Resources department**, a leading multinational corporation.\n",
        "\n",
        "Your toolkit includes:\n",
        "- Conversational AI technology\n",
        "- Python libraries\n",
        "- The powerful **GPT model from OpenAI**\n",
        "- The user-friendly **Gradio UI**\n",
        "\n",
        "Your mission is to integrate these advanced tools to **transform HR processes**, creating a more streamlined and efficient workflow within Nestl√©.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Task  \n",
        "Your task is to develop a **conversational chatbot** that answers queries about Nestl√©'s HR reports efficiently.\n",
        "\n",
        "You must:\n",
        "- Use **Python libraries**, **OpenAI's GPT model**, and **Gradio UI**\n",
        "- Create an interface that extracts and processes information from documents\n",
        "- Provide accurate responses to user queries through the chatbot\n",
        "\n",
        "---\n",
        "\n",
        "## üõ†Ô∏è Action Steps  \n",
        "\n",
        "- ‚úÖ Import essential tools and set up OpenAI's API environment  \n",
        "- ‚úÖ Load Nestl√©'s HR policy using `PyPDFLoader` and split it for easy processing  \n",
        "- ‚úÖ Create vector representations for text chunks using **ChromaDB** and **OpenAI's embeddings**  \n",
        "- ‚úÖ Build a question-answering system using the **GPT-3.5 Turbo model** to retrieve answers  \n",
        "- ‚úÖ Create a **prompt template** to guide the chatbot‚Äôs responses  \n",
        "- ‚úÖ Use **Gradio** to build a user-friendly chatbot interface for interaction and information retrieval  \n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Result  \n",
        "Upon completing this project, you will submit a `.ipynb` file demonstrating your ability to use advanced AI and machine learning technologies to develop a conversational chatbot.\n",
        "\n",
        "Your submission must include:\n",
        "- Setting up the programming environment  \n",
        "- Processing text documents  \n",
        "- Creating vector representations  \n",
        "- Building a question-answering system  \n",
        "- Designing a **Gradio interface** for effective interaction  \n",
        "\n",
        "Ensure the interface is **clear, usable, and accurate** in retrieving relevant information from Nestl√©‚Äôs HR policy.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "GiR0ng62svrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Requirements Breakdown\n",
        "\n",
        "You're building a smart **HR assistant** that can read the **Nestl√© HR policy PDF** and answer employee questions like:\n",
        "- ‚ÄúWhat is Nestl√©‚Äôs policy on promotions?‚Äù\n",
        "- ‚ÄúWhat does Nestl√© offer for employee training?‚Äù\n",
        "\n",
        "This involves:\n",
        "- üóÉÔ∏è Extracting text from the PDF  \n",
        "- üî¢ Converting text chunks into numerical format (embeddings)  \n",
        "- üß† Storing those embeddings in a retrievable way (Chroma DB)  \n",
        "- üí¨ Asking GPT to find answers using those chunks  \n",
        "- üñºÔ∏è Displaying this interaction using Gradio  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "lZreg7yi2dOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Set Up Environment\n",
        "\n",
        "## Import essential tools and set up OpenAI API's environment\n",
        "\n",
        "- Install required packages (`openai`, `langchain`, `chromadb`, `PyPDFLoader`, `gradio`, etc.)  \n",
        "- Set your OpenAI API key securely using Colab Secrets  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ev-EMDgN12U7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OInV06TArYw8"
      },
      "outputs": [],
      "source": [
        "# Step 2: Setup environment\n",
        "\n",
        "# 2A: Install necessary libraries\n",
        "# openai ‚Üí to connect to GPT-3.5 Turbo via API\n",
        "# pypdf ‚Üí to split up Nestle's HR policy for easier processing, used by LangChain's PDF loader\n",
        "# chromadb ‚Üí use with OpenAI's Embeddings to create vector representations of chunks of text from the PDF that can be stored and searched for\n",
        "# gradio ‚Üí to build user-friendly chatbot interface, enabling interaction and information retrieval\n",
        "# langchain ‚Üí for handling document loading, splitting, and retrieval logic\n",
        "# tiktoken ‚Üí used internally by OpenAI for counting tokens (needed in retrieval chains)\n",
        "# langchain_community ‚Üí homes the Chroma integration\n",
        "# langchain-openai ‚Üí homes the OpenAI embeddings wrapper\n",
        "\n",
        "!pip install --quiet openai pypdf chromadb gradio langchain tiktoken langchain-community langchain-openai\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n"
      ],
      "metadata": {
        "id": "Gw5cf2COwQ6D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2B: Access my OpenAI API key securely using Colab Secrets\n",
        "# Avoids typing my key manually or exposing it in the notebook\n",
        "\n",
        "from google.colab import userdata # access my stored keys in Colab\n",
        "from openai import OpenAI         # new OpenAI client class\n",
        "\n",
        "api_key = userdata.get(\"OpenAI\")  # securely fetch my key from Secrets\n",
        "client = OpenAI(api_key=api_key)  # pass it into the OpenAI client directly\n"
      ],
      "metadata": {
        "id": "P57h2l1Tu-4c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2C: Define get_completion function using the updated SDK and secure key\n",
        "\n",
        "from google.colab import userdata               # use Colab's secure key store\n",
        "from openai import OpenAI                       # import the new OpenAI client\n",
        "\n",
        "api_key = userdata.get(\"OpenAI\")                # securely fetch my key from Secrets\n",
        "client = OpenAI(api_key=api_key)                # build a working OpenAI client with that key\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):  # send the prompt using the new SDK style\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response.choices[0].message.content   # extract and return the assistant's reply\n"
      ],
      "metadata": {
        "id": "pd2J2Ca32Hhv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Step 1 E2E\n",
        "\n",
        "get_completion(\"What is the purpose of a human resources policy?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "uxvonduXwpv8",
        "outputId": "6f18b4dc-6770-4545-bfa8-4c45d1c50c0d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The purpose of a human resources policy is to provide guidelines and procedures for managing employees in a fair, consistent, and legally compliant manner. These policies help to ensure that employees are treated fairly, that their rights are protected, and that the organization operates in accordance with relevant laws and regulations. Additionally, human resources policies can help to promote a positive work environment, clarify expectations for employees, and support the overall goals and objectives of the organization.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Load and Split the PDF\n",
        "\n",
        "## Load Nestle's HR Policy using PyPDFLoader and split for easy processing.\n",
        "\n",
        "Use LangChain‚Äôs PyPDFLoader to extract text from the Nestl√© HR policy. Then, break the content into smaller chunks.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "N66x6P7D1tSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3A: Install addtl requiredLangChain package\n",
        "#!pip install --quiet langchain langchain-community"
      ],
      "metadata": {
        "id": "UZLD3LJn89J6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3B: Import LangChain's PDF loader and text splitter\n",
        "#from langchain.document_loaders import PyPDFLoader\n",
        "#from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "ZSkhmKPT6sGU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "local file location: file:///C:/Users/aimee/OneDrive/Documents/AppliedGenAI/Building%20LLM%20Applications/Assessment_1/1728286846_the_nestle_hr_policy_pdf_2012.pdf"
      ],
      "metadata": {
        "id": "xSH5KLLK7K-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3A: Upload HR policy PDF to Colab environment to get the correct path\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "utaSAw047PNf",
        "outputId": "041bf215-2b7e-4266-d480-4e67751c389d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fc93c166-ab7f-4125-bab1-036776dd3b53\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fc93c166-ab7f-4125-bab1-036776dd3b53\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1728286846_the_nestle_hr_policy_pdf_2012.pdf to 1728286846_the_nestle_hr_policy_pdf_2012 (1).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3B: Load the Nestl√© HR policy document and define the path\n",
        "pdf_path = \"/content/1728286846_the_nestle_hr_policy_pdf_2012.pdf\" ### update path if needed ###\n",
        "\n",
        "# Use PyPDFLoader from LangChain to extract PDF content\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "\n",
        "# Step 3B: Extract the document and return a list of LangChain Document objects\n",
        "# Each page will become a separate document object (1 per PDF pg)\n",
        "pages = loader.load()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGV0_4d76z5_",
        "outputId": "679397c4-6d98-4929-f0a2-d0abf342ebfa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 8 pages from the PDF.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST: Check how many pages were loaded\n",
        "print(f\"Loaded {len(pages)} pages from the PDF.\")"
      ],
      "metadata": {
        "id": "PJFd-ha9omXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST: Show characters 100-200 on page 2\n",
        "print(pages[2].page_content[100:200])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfG1JJvHxA4L",
        "outputId": "45c8c5d7-e970-4516-c070-46f3d287b417"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uccess and nothing can be \n",
            "achieved without their engagement. \n",
            "This document encompasses the guideli\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST: Print the length of the first embedded document\n",
        "model_name = \"text-embedding-3-large\"\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", api_key=api_key)\n",
        "text = pages[0].page_content\n",
        "embedding = embeddings.embed_query(text)\n",
        "print(len(embedding))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcXNf42vorFU",
        "outputId": "405d29e9-830d-4b3e-f312-cebd0f923aa7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3C: Define how to chunk the text\n",
        "# I want chunks that are not too long, and that overlap slightly to preserve context\n",
        "text_splitter = RecursiveCharacterTextSplitter( #defines HOW to chunk the text\n",
        "    chunk_size=1000,      # max characters per chunk (adjustable)\n",
        "    chunk_overlap=100     # overlap to keep context from spilling over boundaries (adjustable)\n",
        ")\n",
        "\n",
        "# TEST: Text_splitter was created successfully\n",
        "print(type(text_splitter))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8OTAxM39saA",
        "outputId": "47449b1e-21a2-409d-f70b-34e2508ff91d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_text_splitters.character.RecursiveCharacterTextSplitter'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3D: Split all pages into smaller chunks\n",
        "# This will give me a list of Document chunks, ready to be embedded later\n",
        "chunks = text_splitter.split_documents(pages)\n",
        "\n",
        "# TEST: Preview the third chunk to see how it looks\n",
        "# Access the first element of the slice (which is the third chunk) and then its page_content\n",
        "print(chunks[2].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2FKO99s_gCV",
        "outputId": "7a3fc4e3-2a13-4432-956a-77879eb74978"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Nestl√© Human Resources Policy\n",
            "1\n",
            "At Nestl√©, we recognize that our employees \n",
            "are the key to our success and nothing can be \n",
            "achieved without their engagement. \n",
            "This document encompasses the guidelines \n",
            "which constitute a solid basis for effective Human \n",
            "Resources Management throughout the Nestl√© \n",
            "Group around the world. It explains to all Nestl√© \n",
            "employees the vision and mission of the Human \n",
            "Resources function and illustrates every aspect of \n",
            "the Nestl√© employee lifecycle. \n",
            "The Nestl√© Management and Leadership \n",
            "Principles inspire all the Nestl√© employees in their \n",
            "actions and in their dealings with others. The \n",
            "Corporate Business Principles refer to all the basic \n",
            "principles which Nestl√© endorses and subscribes \n",
            "to on a worldwide basis. Both these documents \n",
            "are the pillars on which the present policy has \n",
            "been built.\n",
            "The implementation of this policy will be \n",
            "inspired by sound judgement, compliance with \n",
            "local market laws and common sense, taking into\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf2fa396",
        "outputId": "a4109203-d8f9-4647-d6b6-d546bce7a26e"
      },
      "source": [
        "# TEST: Print the content of the first 5 chunks\n",
        "for i, chunk in enumerate(chunks[:3]): #adds a counter; returns pairs of (index, value) for each item in the list; \"for\" loop iterates through the pairs\n",
        "  print(f\"--- Chunk {i+1} ---\") #prints a header for each chunk\n",
        "  print(chunk.page_content) #prints text content of the current chunk\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Chunk 1 ---\n",
            "Policy\n",
            "Mandatory\n",
            "September‚Äâ‚Äâ2012\n",
            "The Nestl√©  \n",
            "Human Resources Policy\n",
            "--- Chunk 2 ---\n",
            "Policy\n",
            "Mandatory\n",
            "September‚Äâ\n",
            "‚Äâ20\n",
            "12\n",
            "Issuing‚Äâdepartement\n",
            "Hum\n",
            "an Resources\n",
            "Target‚Äâaudience‚Äâ\n",
            "All\n",
            " employees\n",
            "Approver\n",
            "Executive Board, Nestl√© S.A.\n",
            "Repository\n",
            "All Nestl√© Principles and Policies, Standards and  \n",
            "Guidelines can be found in the Centre online repository at:  \n",
            "http://intranet.nestle.com/nestledocs\n",
            "Copyright\n",
            "‚Äâand‚Äâconfidentiality\n",
            "Al\n",
            "l rights belong to Nestec Ltd., Vevey, Switzerland.\n",
            "¬© 2012, Nestec Ltd.\n",
            "Design\n",
            "Nestec Ltd., Corporate Identity & Design,  \n",
            "Vevey, Switzerland\n",
            "Production\n",
            "brain‚Äôprint GmbH, Switzerland\n",
            "Paper\n",
            "This report is printed on BVS, a paper produced  \n",
            "from well-managed forests and other controlled sources  \n",
            "certified by the Forest Stewardship Council (FSC).\n",
            "--- Chunk 3 ---\n",
            "The Nestl√© Human Resources Policy\n",
            "1\n",
            "At Nestl√©, we recognize that our employees \n",
            "are the key to our success and nothing can be \n",
            "achieved without their engagement. \n",
            "This document encompasses the guidelines \n",
            "which constitute a solid basis for effective Human \n",
            "Resources Management throughout the Nestl√© \n",
            "Group around the world. It explains to all Nestl√© \n",
            "employees the vision and mission of the Human \n",
            "Resources function and illustrates every aspect of \n",
            "the Nestl√© employee lifecycle. \n",
            "The Nestl√© Management and Leadership \n",
            "Principles inspire all the Nestl√© employees in their \n",
            "actions and in their dealings with others. The \n",
            "Corporate Business Principles refer to all the basic \n",
            "principles which Nestl√© endorses and subscribes \n",
            "to on a worldwide basis. Both these documents \n",
            "are the pillars on which the present policy has \n",
            "been built.\n",
            "The implementation of this policy will be \n",
            "inspired by sound judgement, compliance with \n",
            "local market laws and common sense, taking into\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Create Embeddings & Store Them in Chroma\n",
        "\n",
        "##Create vector representations for text chunks using Chroma dB and OpenAI's embeddings.\n",
        "\n",
        "Use OpenAI‚Äôs embedding model (such as `text-embedding-3-large`) to:\n",
        "\n",
        "1. üî¢ **Convert each chunk into a numerical vector**  \n",
        "   This transforms the text into a format that can be compared mathematically for similarity.\n",
        "\n",
        "2. üß† **Store the vectors in ChromaDB**  \n",
        "   This allows the system to **retrieve the most relevant chunks** when users ask questions, based on vector similarity.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "LrdyzDe83v0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4a - Store my Chroma DB in GDrive so it persists across sessions\n",
        "\n",
        "Created the folder\n",
        "\n",
        "import os\n",
        "\n",
        "os.makedirs(persist_directory, exist_ok=True)"
      ],
      "metadata": {
        "id": "vZy6-CFNvWqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount my Google Drive so Colab can read/write to it.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os # Import the os module\n",
        "\n",
        "# tells the rest of the code where to save/load the DB\n",
        "persist_directory = \"/content/drive/MyDrive/ai_powered_hr_assistant/chroma_nestle\"\n",
        "\n",
        "# Validate that the path is ready.\n",
        "print(\"Chroma DB folder set to:\", persist_directory)\n",
        "print(\"Folder exists?\", os.path.isdir(persist_directory))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qQUCv_WvIOc",
        "outputId": "545987be-a1b4-4595-cf5e-2245b1c58852"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Chroma DB folder set to: /content/drive/MyDrive/ai_powered_hr_assistant/chroma_nestle\n",
            "Folder exists? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4b: Build the embeddings object"
      ],
      "metadata": {
        "id": "BkQdcJA20cpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2TWPTg5bxi5",
        "outputId": "2f9eb8d5-618a-41db-986d-766c6f3d1ea7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-0.2.5-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: langchain-core>=0.3.70 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma) (0.3.74)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma) (2.0.2)\n",
            "Requirement already satisfied: chromadb>=1.0.9 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma) (1.0.16)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (2.11.7)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (0.35.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.14.1)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.22.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.36.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.21.4)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.74.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.16.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (33.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (3.11.1)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.25.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.70->langchain-chroma) (0.4.12)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.70->langchain-chroma) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.70->langchain-chroma) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=1.0.9->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.70->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (0.26.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.5.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.10)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.70->langchain-chroma) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.70->langchain-chroma) (0.23.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.36.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.9->langchain-chroma) (0.57b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (0.34.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (1.1.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (1.1.7)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (3.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.6.1)\n",
            "Downloading langchain_chroma-0.2.5-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: langchain-chroma\n",
            "Successfully installed langchain-chroma-0.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma"
      ],
      "metadata": {
        "id": "8XfElFl-b01C"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed + persist (OpenAI‚Äôs current recs: text-embedding-3-small/large)\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", api_key=api_key) #load API key again if needed\n",
        "\n",
        "# Pass the embeddings model directly during Chroma initialization\n",
        "vectordb = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=persist_directory) # Docs are auto persisted in new versions of Chroma, no need for vectordb.persist()"
      ],
      "metadata": {
        "id": "1DMZfs5Ovyx8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the vector store into a Retriever object\n",
        "# The Chroma vector store object (vectordb) has a method to easily convert it into a retriever\n",
        "\n",
        "retriever = vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "oP9_K3yXr_ws"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "246d8084",
        "outputId": "3858cf39-a8a5-4b70-887a-e6d00d20bfca"
      },
      "source": [
        "# TEST the vector db by performing a similarity search\n",
        "query = \"What is Nestl√©'s policy on employee training?\"\n",
        "\n",
        "# Print the content of the retrieved documents to see if they are relevant\n",
        "print(f\"Retrieved {len(docs)} documents:\")\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"--- Retrieved Document {i+1} ---\")\n",
        "    print(doc.page_content)\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved 4 documents:\n",
            "--- Retrieved Document 1 ---\n",
            "The Nestl√© Human Resources Policy\n",
            "1\n",
            "At Nestl√©, we recognize that our employees \n",
            "are the key to our success and nothing can be \n",
            "achieved without their engagement. \n",
            "This document encompasses the guidelines \n",
            "which constitute a solid basis for effective Human \n",
            "Resources Management throughout the Nestl√© \n",
            "Group around the world. It explains to all Nestl√© \n",
            "employees the vision and mission of the Human \n",
            "Resources function and illustrates every aspect of \n",
            "the Nestl√© employee lifecycle. \n",
            "The Nestl√© Management and Leadership \n",
            "Principles inspire all the Nestl√© employees in their \n",
            "actions and in their dealings with others. The \n",
            "Corporate Business Principles refer to all the basic \n",
            "principles which Nestl√© endorses and subscribes \n",
            "to on a worldwide basis. Both these documents \n",
            "are the pillars on which the present policy has \n",
            "been built.\n",
            "The implementation of this policy will be \n",
            "inspired by sound judgement, compliance with \n",
            "local market laws and common sense, taking into\n",
            "\n",
            "\n",
            "--- Retrieved Document 2 ---\n",
            "The Nestl√© Human Resources Policy\n",
            "1\n",
            "At Nestl√©, we recognize that our employees \n",
            "are the key to our success and nothing can be \n",
            "achieved without their engagement. \n",
            "This document encompasses the guidelines \n",
            "which constitute a solid basis for effective Human \n",
            "Resources Management throughout the Nestl√© \n",
            "Group around the world. It explains to all Nestl√© \n",
            "employees the vision and mission of the Human \n",
            "Resources function and illustrates every aspect of \n",
            "the Nestl√© employee lifecycle. \n",
            "The Nestl√© Management and Leadership \n",
            "Principles inspire all the Nestl√© employees in their \n",
            "actions and in their dealings with others. The \n",
            "Corporate Business Principles refer to all the basic \n",
            "principles which Nestl√© endorses and subscribes \n",
            "to on a worldwide basis. Both these documents \n",
            "are the pillars on which the present policy has \n",
            "been built.\n",
            "The implementation of this policy will be \n",
            "inspired by sound judgement, compliance with \n",
            "local market laws and common sense, taking into\n",
            "\n",
            "\n",
            "--- Retrieved Document 3 ---\n",
            "The Nestl√© Human Resources Policy\n",
            "2\n",
            "Line managers have the prime responsibility for \n",
            "building and sustaining an environment where \n",
            "people have a sense of personal commitment \n",
            "to their work and give their best to ensure our \n",
            "Company‚Äôs success. They care for and develop \n",
            "the leaders of tomorrow.\n",
            "Line managers decide on all people matters \n",
            "under their influence, within the boundaries set \n",
            "by the policies and principles, acting as the final \n",
            "decision makers.\n",
            "The Human Resources (HR) structure \n",
            "enables and empowers them in establishing \n",
            "business needs and their corresponding people \n",
            "requirements. \n",
            "Therefore, the mission of HR managers and \n",
            "their teams is to provide professional guidance \n",
            "to line managers aiming to deliver superior \n",
            "business results by optimising the performance \n",
            "of our people, while ensuring exemplary working \n",
            "conditions. \n",
            "With a ‚ÄòNestl√© in the Market‚Äô (NiM) approach, \n",
            "HR has adopted a streamlined approach to \n",
            "ensuring functional leadership and the highest\n",
            "\n",
            "\n",
            "--- Retrieved Document 4 ---\n",
            "The Nestl√© Human Resources Policy\n",
            "2\n",
            "Line managers have the prime responsibility for \n",
            "building and sustaining an environment where \n",
            "people have a sense of personal commitment \n",
            "to their work and give their best to ensure our \n",
            "Company‚Äôs success. They care for and develop \n",
            "the leaders of tomorrow.\n",
            "Line managers decide on all people matters \n",
            "under their influence, within the boundaries set \n",
            "by the policies and principles, acting as the final \n",
            "decision makers.\n",
            "The Human Resources (HR) structure \n",
            "enables and empowers them in establishing \n",
            "business needs and their corresponding people \n",
            "requirements. \n",
            "Therefore, the mission of HR managers and \n",
            "their teams is to provide professional guidance \n",
            "to line managers aiming to deliver superior \n",
            "business results by optimising the performance \n",
            "of our people, while ensuring exemplary working \n",
            "conditions. \n",
            "With a ‚ÄòNestl√© in the Market‚Äô (NiM) approach, \n",
            "HR has adopted a streamlined approach to \n",
            "ensuring functional leadership and the highest\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Build the Q&A Pipeline\n",
        "\n",
        "##*Build a question-answering system using the GPT-3.5 Turbo model to retrieve answers from text chunks.*\n",
        "\n",
        "\n",
        "\n",
        "----\n",
        "Use **LangChain‚Äôs `RetrievalQA`** (or a similar approach) to create an intelligent question-answering flow.\n",
        "\n",
        "The pipeline should:\n",
        "\n",
        "1. **Take the user's question**  \n",
        "   Accept natural language input from the user (e.g., ‚ÄúWhat is Nestl√©'s policy on promotions?‚Äù)\n",
        "\n",
        "2. **Retrieve the most relevant chunks from ChromaDB**  \n",
        "   Use similarity search to find the document sections most related to the question\n",
        "\n",
        "3. **Pass those chunks to GPT-3.5 Turbo as context**  \n",
        "   Feed the retrieved text into the model so it can generate a grounded, accurate answer\n"
      ],
      "metadata": {
        "id": "ZxWDmGOl31J0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the language model (GPT-3.5 Turbo)\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, api_key=api_key)"
      ],
      "metadata": {
        "id": "2w-Ra69ip1pK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa89bcbe",
        "outputId": "b492fcbd-9543-4317-e9a8-02f8d4c09190"
      },
      "source": [
        "# TEST the LLM connectivity\n",
        "print(llm.invoke(\"Hello, how are you?\"))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with anything you need. How can I assist you today?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 13, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C3X3wVyKJIsVeNhCGZcq7cLwByEmQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--5c0bf0ba-e660-4d77-8a4e-033c4305f84c-0' usage_metadata={'input_tokens': 13, 'output_tokens': 37, 'total_tokens': 50, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e62a7eec"
      },
      "source": [
        "# Assemble the Q&A chain\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Make sure the retriever object is created:\n",
        "# retriever = vectordb.as_retriever()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST: Retrieve relevant documents from the vectordb using similarity search with RetrievalQA\n",
        "\n",
        "query = \"What ensures the success of Nestle as a company?\"\n",
        "docs = vectordb.similarity_search(query)\n",
        "\n",
        "# Retrieve only the top 3 most relevant documents\n",
        "docs = vectordb.similarity_search(query, k=3)\n",
        "\n",
        "# Print the content of the retrieved documents to see if they are relevant\n",
        "print(f\"Retrieved {len(docs)} documents:\")\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"--- Retrieved Document {i+1} ---\")\n",
        "    print(doc.page_content)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "QoTQu0Cf338b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2274796-084e-49b0-cb26-5bb205d0a4c1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved 3 documents:\n",
            "--- Retrieved Document 1 ---\n",
            "of a global company with the creativity and \n",
            "knowledge of a local business. As a result, people \n",
            "can have far-reaching influence every day and \n",
            "explore their full long-term potential, propelled by \n",
            "continual support and a collaborative approach by \n",
            "line managers and employees.\n",
            "Corporate policy: \n",
            "Nestl√© on the Move\n",
            " A flexible and dynamic organisation\n",
            "\n",
            "\n",
            "--- Retrieved Document 2 ---\n",
            "of a global company with the creativity and \n",
            "knowledge of a local business. As a result, people \n",
            "can have far-reaching influence every day and \n",
            "explore their full long-term potential, propelled by \n",
            "continual support and a collaborative approach by \n",
            "line managers and employees.\n",
            "Corporate policy: \n",
            "Nestl√© on the Move\n",
            " A flexible and dynamic organisation\n",
            "\n",
            "\n",
            "--- Retrieved Document 3 ---\n",
            "The Nestl√© Human Resources Policy\n",
            "1\n",
            "At Nestl√©, we recognize that our employees \n",
            "are the key to our success and nothing can be \n",
            "achieved without their engagement. \n",
            "This document encompasses the guidelines \n",
            "which constitute a solid basis for effective Human \n",
            "Resources Management throughout the Nestl√© \n",
            "Group around the world. It explains to all Nestl√© \n",
            "employees the vision and mission of the Human \n",
            "Resources function and illustrates every aspect of \n",
            "the Nestl√© employee lifecycle. \n",
            "The Nestl√© Management and Leadership \n",
            "Principles inspire all the Nestl√© employees in their \n",
            "actions and in their dealings with others. The \n",
            "Corporate Business Principles refer to all the basic \n",
            "principles which Nestl√© endorses and subscribes \n",
            "to on a worldwide basis. Both these documents \n",
            "are the pillars on which the present policy has \n",
            "been built.\n",
            "The implementation of this policy will be \n",
            "inspired by sound judgement, compliance with \n",
            "local market laws and common sense, taking into\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Prompt Template\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "Use three sentences maximum.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Answer:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zkmr4GqSp-MQ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a PromptTemplate object from the prompt_template string\n",
        "# Takes human-readable prompt instructions and turns it into a machine-readable object that L.C.chain can use to dynamically construct the final prompt sent to GPT-3.5 Turbo during the Q&A process.\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(prompt_template) #takes raw string input and converts into PromptTemplate that L.C. can work with\n",
        "\n",
        "# This method parses the string, identifies the placeholders, & sets up the structure so when P.T. is used later, L.C. knows where to inject the actual document context and users' question.\n",
        "# Required b/c L.C. chains, like RetrievalQA, is designed to work w/ structured objects"
      ],
      "metadata": {
        "id": "W_PEHMDXwO-7"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the RetrievalQA chain & assign it to the qa_chain variable\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    # initialized model object = GPT-3.5 Turbo with temperature=0\n",
        "    llm,\n",
        "    #passes retriever object (created from vectordb); tells the chain where to get the relevant document chunks from when a query comes in\n",
        "    retriever=retriever,\n",
        "    # Optional: returns the chunks used to generate the answer\n",
        "    return_source_documents=True,\n",
        "    # RetrievalQA uses chain type=\"stuff,\" by default. This part tells the \"stuff\" chain to use the custom QA_CHAIN_PROMPT as the template for the prompt it constructs.\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT} # Pass the prompt template to the chain. allows you to pass additional parameters to the underlying chain type being used by RetrievalQA\n",
        ")"
      ],
      "metadata": {
        "id": "Fb8JmkidwRwu"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST the chain by asking a question\n",
        "query = \"What ensures the success of Nestle as a company?\"\n",
        "response = qa_chain.invoke({\"query\": query})\n",
        "\n",
        "# Print the Question and Answer\n",
        "print(\"Question:\", query)\n",
        "print(\"Answer:\", response['result'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo9Tq1imwVIg",
        "outputId": "b462e173-a643-405e-a62f-2f8e92e5bd9d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What ensures the success of Nestle as a company?\n",
            "Answer: The key to Nestl√©'s success lies in recognizing that employees are crucial to achieving their goals and engaging them effectively. The company's Human Resources Policy provides guidelines for effective management and leadership principles that inspire employees. Nestl√©'s adherence to Corporate Business Principles and implementation of policies with sound judgement and compliance with local laws also contribute to its success.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Print source documents\n",
        "print(\"\\nSource Documents:\")\n",
        "for doc in response['source_documents']:\n",
        "     print(doc.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfh7txbx2QW9",
        "outputId": "a6a5b59b-1196-4fb4-efac-856f20d93df0"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Source Documents:\n",
            "of a global company with the creativity and \n",
            "knowledge of a local business. As a result, people \n",
            "can have far-reaching influence every day and \n",
            "explore their full long-term potential, propelled by \n",
            "continual support and a collaborative approach by \n",
            "line managers and employees.\n",
            "Corporate policy: \n",
            "Nestl√© on the Move\n",
            " A flexible and dynamic organisation\n",
            "of a global company with the creativity and \n",
            "knowledge of a local business. As a result, people \n",
            "can have far-reaching influence every day and \n",
            "explore their full long-term potential, propelled by \n",
            "continual support and a collaborative approach by \n",
            "line managers and employees.\n",
            "Corporate policy: \n",
            "Nestl√© on the Move\n",
            " A flexible and dynamic organisation\n",
            "The Nestl√© Human Resources Policy\n",
            "1\n",
            "At Nestl√©, we recognize that our employees \n",
            "are the key to our success and nothing can be \n",
            "achieved without their engagement. \n",
            "This document encompasses the guidelines \n",
            "which constitute a solid basis for effective Human \n",
            "Resources Management throughout the Nestl√© \n",
            "Group around the world. It explains to all Nestl√© \n",
            "employees the vision and mission of the Human \n",
            "Resources function and illustrates every aspect of \n",
            "the Nestl√© employee lifecycle. \n",
            "The Nestl√© Management and Leadership \n",
            "Principles inspire all the Nestl√© employees in their \n",
            "actions and in their dealings with others. The \n",
            "Corporate Business Principles refer to all the basic \n",
            "principles which Nestl√© endorses and subscribes \n",
            "to on a worldwide basis. Both these documents \n",
            "are the pillars on which the present policy has \n",
            "been built.\n",
            "The implementation of this policy will be \n",
            "inspired by sound judgement, compliance with \n",
            "local market laws and common sense, taking into\n",
            "The Nestl√© Human Resources Policy\n",
            "1\n",
            "At Nestl√©, we recognize that our employees \n",
            "are the key to our success and nothing can be \n",
            "achieved without their engagement. \n",
            "This document encompasses the guidelines \n",
            "which constitute a solid basis for effective Human \n",
            "Resources Management throughout the Nestl√© \n",
            "Group around the world. It explains to all Nestl√© \n",
            "employees the vision and mission of the Human \n",
            "Resources function and illustrates every aspect of \n",
            "the Nestl√© employee lifecycle. \n",
            "The Nestl√© Management and Leadership \n",
            "Principles inspire all the Nestl√© employees in their \n",
            "actions and in their dealings with others. The \n",
            "Corporate Business Principles refer to all the basic \n",
            "principles which Nestl√© endorses and subscribes \n",
            "to on a worldwide basis. Both these documents \n",
            "are the pillars on which the present policy has \n",
            "been built.\n",
            "The implementation of this policy will be \n",
            "inspired by sound judgement, compliance with \n",
            "local market laws and common sense, taking into\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST with a different question\n",
        "query = \"What are ‚ÄúNestl√© Management and Leadership Principles?\"\n",
        "response = qa_chain.invoke({\"query\": query})\n",
        "\n",
        "# Print the Question and Answer\n",
        "print(\"Question:\", query)\n",
        "print(\"Answer:\", response['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj3EizZo2p-n",
        "outputId": "db20efb4-251a-4630-f811-76f01b0276a4"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are ‚ÄúNestl√© Management and Leadership Principles?\n",
            "Answer: The Nestl√© Management and Leadership Principles inspire all Nestl√© employees in their actions and dealings with others. They are the pillars on which the present policy has been built. They refer to the basic principles that Nestl√© endorses and subscribes to on a worldwide basis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Create a Gradio Interface\n",
        "\n",
        "## *Use Gradio to build a user-friendly chatbot interface, enabling interaction and information retrieval.*\n",
        "\n",
        "Allow users to type in questions and receive answers from the chatbot.\n",
        "\n",
        "Use `gr.Interface()` with the following components:\n",
        "\n",
        "- `gr.Textbox()` as the **input**  \n",
        "- `gr.Textbox()` or `gr.HTML()` as the **output**  \n",
        "- Your custom **Q&A function** as the **backend logic**\n",
        "\n",
        "This interface will let users interact with your AI assistant through a simple, user-friendly web app.\n"
      ],
      "metadata": {
        "id": "SYFry5md4N_1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dGdKQXcI4Ww_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Submit\n",
        "\n",
        "Make sure your final `.ipynb` notebook meets the following requirements:\n",
        "\n",
        "- üí¨ Has **comments explaining each step** in your workflow  \n",
        "- üîÑ Shows the **full pipeline working** from document loading to answering questions  \n",
        "- üß™ Includes **example questions and answers** about Nestl√©‚Äôs HR policy\n",
        "\n",
        "Your notebook should clearly demonstrate your understanding of how to build an AI-powered Q&A assistant using OpenAI, LangChain, Chroma, and Gradio."
      ],
      "metadata": {
        "id": "8QSPQ1904XJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push to Git"
      ],
      "metadata": {
        "id": "ciIY2t4fDT3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üîê Set up Git identity (only needs to be done once per Colab session)\n",
        "#!git config --global user.name \"afarabee\"\n",
        "#!git config --global user.email \"aimee.farabee@crl.com\"\n"
      ],
      "metadata": {
        "id": "7frC-AS94ecK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone #################token#############"
      ],
      "metadata": {
        "id": "5G8Yxp-SDq2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move your notebook into the repo folder\n",
        "#!mv /content/AI_Powered_HR_Assistant.ipynb /content/ai_powered_hr_assistant/\n"
      ],
      "metadata": {
        "id": "3gFoOAJhFUda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!ls /content/*.ipynb\n"
      ],
      "metadata": {
        "id": "tuQhx3sDFgqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fZ55LC4-Frky"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}